{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f03ff6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import os\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b88fdeb",
   "metadata": {},
   "source": [
    "## Using Splinter & ChromeDriver Manager to Scrape Mars Website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8e883ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using splinter to scrape the web browser\n",
    "from splinter import Browser\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64f36cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - ====== WebDriver manager ======\n",
      "[WDM] - Current google-chrome version is 102.0.5005\n",
      "[WDM] - Get LATEST chromedriver version for 102.0.5005 google-chrome\n",
      "[WDM] - About to download new driver from https://chromedriver.storage.googleapis.com/102.0.5005.61/chromedriver_win32.zip\n",
      "[WDM] - Driver has been saved in cache [C:\\Users\\mpddr\\.wdm\\drivers\\chromedriver\\win32\\102.0.5005.61]\n"
     ]
    }
   ],
   "source": [
    "# Setup splinter\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be69ffe",
   "metadata": {},
   "source": [
    "## Mars News Headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ce1b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://redplanetscience.com/'\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ecba66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  x is page number denotation\n",
    "pg = []\n",
    "for x in range(1, 6):\n",
    "    \n",
    "    pg.append (x)\n",
    "    html = browser.html\n",
    "    soup = bs(html, 'html.parser')\n",
    "    \n",
    "    data_text = soup.find_all('div', class_ = 'list_text')\n",
    "#     c_title = soup.find_all('div', class_='content_title')\n",
    "#     title_date = soup.find_all('div', class_='list_date')\n",
    "    cont_date =[]\n",
    "    cont_title=[]\n",
    "    cont_body=[]\n",
    "\n",
    "    for data in data_text:\n",
    "        title_date = data.find('div','list_date')\n",
    "        cont_date.append (title_date)\n",
    "        titles = data.find('div','content_title')\n",
    "        cont_title.append (titles)\n",
    "        body = data.find('div', 'article_teaser_body')\n",
    "        cont_body.append (body)\n",
    "#         print('page:', x, '-------------')\n",
    "#         print(cont_title)\n",
    "#         print(cont_date)\n",
    "\n",
    "print('page:', pg[0], '-------------')\n",
    "print(f\"Latest News Title: {cont_title[0].text}\")\n",
    "print(f\"Latest News Paragraph: {cont_body[0].text}\")\n",
    "print(f\"Latest News Date: {cont_date[0].text}\")\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107469ab",
   "metadata": {},
   "source": [
    "### Another way to Scrape website "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa282a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method needs CHromeDriver Manager too.. Requests to wesbite without chromedriver dont seem to work. \n",
    "url = 'https://redplanetscience.com/'\n",
    "browser.visit(url)\n",
    "\n",
    "#  Create the html object\n",
    "html = browser.html\n",
    "\n",
    "#  use Beautiful soup to parse and find required titles, dates etc.\n",
    "soup = bs(html, 'html.parser')\n",
    "Latest_news_title = soup.find_all('div', class_='content_title')[0].text\n",
    "Latest_news_paragraph = soup.find_all('div', class_='article_teaser_body')[0].text\n",
    "Latest_News_Date = soup.find_all('div', class_='list_date')[0].text\n",
    "\n",
    "# Print results\n",
    "print(f\"Latest News Title: {Latest_news_title}\")\n",
    "print(f\"Latest News Paragraph: {Latest_news_paragraph}\")\n",
    "print(f\"Latest News Date: {Latest_News_Date}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc408a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the open browser\n",
    "# browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82eab006",
   "metadata": {},
   "source": [
    "## JPL Mars Featured Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3e3495",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://spaceimages-mars.com/'\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da149f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Create the html object\n",
    "html = browser.html\n",
    "\n",
    "#  use Beautiful soup to parse and find required titles, dates etc.\n",
    "soup = bs(html, 'html.parser')\n",
    "floating_txt_area = soup.find_all('div', class_='floating_text_area')\n",
    "floating_txt_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5b7289",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in floating_txt_area:\n",
    "    a = img.find('a')\n",
    "    image = a['href']\n",
    "    print(image)\n",
    "featured_image_url = 'https://spaceimages-mars.com/' + image\n",
    "print (f\"Featured_image_url):{featured_image_url}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af20ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5399c6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(featured_image_url, stream=True)\n",
    "with open('outputs/featuredimage.jpg', 'wb') as out_file:\n",
    "    shutil.copyfileobj(response.raw, out_file)\n",
    "\n",
    "Image(url= 'outputs/featuredimage.jpg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8bc2de",
   "metadata": {},
   "source": [
    "## Mars Facts - Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1939e888",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb087713",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://galaxyfacts-mars.com/'\n",
    "# browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb49db71",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = pd.read_html(url)\n",
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c932c06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "type (tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bde4b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tables[0]\n",
    "df1 = tables[1]\n",
    "df.columns = ['Facts', 'Mars', 'Earth']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42703777",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns = ['Mars_Facts', 'Value']\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ef87f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mars_facts_html = df.to_html(header = False, index = False)\n",
    "mars_facts_html.replace('\\n', '')\n",
    "print(mars_facts_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceae1427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving html file of the mars facts table\n",
    "df.to_html('mars_facts_table.html', header = False, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15eff6eb",
   "metadata": {},
   "source": [
    "## Scraping for Mars Pictures from url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe42d03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://marshemispheres.com/'\n",
    "browser.visit(url)\n",
    "html = browser.html\n",
    "\n",
    "#  use Beautiful soup to parse and find required titles, dates etc.\n",
    "soup = bs(html, 'html.parser')\n",
    "descrp = soup.find_all('div', class_='description')\n",
    "\n",
    "print(descrp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f19d162",
   "metadata": {},
   "outputs": [],
   "source": [
    "mars_pics_url = []\n",
    "\n",
    "# making a for loop to pull title & image_urls\n",
    "\n",
    "for data in descrp: \n",
    "#     error handling\n",
    "    try: \n",
    "        title = data.find('h3').text\n",
    "        link = data.a['href']\n",
    "        url_link = f\"https://marshemispheres.com/\" + link\n",
    "        browser.visit(url_link)\n",
    "        html = browser.html\n",
    "        soup = bs(html, 'html.parser')\n",
    "        pg_all = soup.find('img', class_=\"wide-image\")\n",
    "        pic_link = pg_all['src']\n",
    "        img_url = f\"https://marshemispheres.com/\" + pic_link\n",
    "        \n",
    "        if (title and pic_link):\n",
    "        \n",
    "            print(title)\n",
    "            print (img_url)\n",
    "            print('---------------------------------------------------------------------------------')\n",
    "\n",
    "            mars_pic_dict = {\n",
    "                'Title':title, \n",
    "                'img_url': img_url\n",
    "            }\n",
    "\n",
    "            mars_pics_url.append(mars_pic_dict)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be78ddae",
   "metadata": {},
   "outputs": [],
   "source": [
    "mars_pics_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5fd3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the requests library to download and save the image from the `img_url` above\n",
    "response = requests.get(mars_pics_url[0]['img_url'], stream=True)\n",
    "with open('outputs/Cerberus.jpg', 'wb') as out_file:\n",
    "    shutil.copyfileobj(response.raw, out_file)\n",
    "Image(url='outputs/Cerberus.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41352808",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(mars_pics_url[1]['img_url'], stream=True)\n",
    "with open('outputs/Schiaparelli.jpg', 'wb') as out_file:\n",
    "    shutil.copyfileobj(response.raw, out_file)\n",
    "Image(url='outputs/Schiaparelli.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feeaa66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(mars_pics_url[2]['img_url'], stream=True)\n",
    "with open('outputs/Syrtis_Major.jpg', 'wb') as out_file:\n",
    "    shutil.copyfileobj(response.raw, out_file)\n",
    "Image(url='outputs/Syrtis_Major.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763dd9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(mars_pics_url[3]['img_url'], stream=True)\n",
    "with open('outputs/Valles_Marineris.jpg', 'wb') as out_file:\n",
    "    shutil.copyfileobj(response.raw, out_file)\n",
    "Image(url='outputs/Valles_Marineris.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83b4fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5c0f15",
   "metadata": {},
   "outputs": [],
   "source": [
    " Mars_dict = {\n",
    "        \"Latest_news_Title\": Latest_news_title,\n",
    "        \"Latest_news_Paragraph\": Latest_news_paragraph,\n",
    "        \"Latest_news_Date\": Latest_News_Date\n",
    "        \"Featured_image_urlge_url\": featured_image_url,\n",
    "        \"Mars_facts_html_table\": mars_facts_html,\n",
    "        \"Hemisphere_images\": mars_pics_url\n",
    "    }\n",
    "Mars_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b092a06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
